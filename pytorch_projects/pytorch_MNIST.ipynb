{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P4aX4LbRqR6Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 64)  # 28*28 from image dimension\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kfKpvrzYrUqF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "        trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "        net = SimpleNet()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "        for epoch in range(2):  # loop over the dataset 2 times\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(trainloader, 0):\n",
        "                inputs, labels = data\n",
        "                optimizer.zero_grad()\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "                    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        print('Finished Training')\n",
        "        torch.save(net.state_dict(), 'modelo_mnist.pth')\n",
        "\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt4b6iFUwHBN",
        "outputId": "c99ba242-2f53-4528-a214-54f4b916d073"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 77007174.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 73415572.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 22555693.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3058851.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "[1,  2000] loss: 0.672\n",
            "[1,  4000] loss: 0.380\n",
            "[1,  6000] loss: 0.318\n",
            "[1,  8000] loss: 0.299\n",
            "[1, 10000] loss: 0.274\n",
            "[1, 12000] loss: 0.242\n",
            "[1, 14000] loss: 0.236\n",
            "[2,  2000] loss: 0.211\n",
            "[2,  4000] loss: 0.190\n",
            "[2,  6000] loss: 0.183\n",
            "[2,  8000] loss: 0.180\n",
            "[2, 10000] loss: 0.172\n",
            "[2, 12000] loss: 0.168\n",
            "[2, 14000] loss: 0.174\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNet()\n",
        "model.load_state_dict(torch.load('modelo_mnist.pth'))\n",
        "model.eval()  # Important to switch the model to evaluation mode\n",
        "images = []\n",
        "\n",
        "for root, dirs, files in os.walk('data'):\n",
        "    for file in files:\n",
        "        base, extension = os.path.splitext(file)\n",
        "        if extension.lower() == '.jpg':\n",
        "            full_path = os.path.join(root, file)\n",
        "            images.append(full_path)\n"
      ],
      "metadata": {
        "id": "b5qKldsPt3Ys"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image):\n",
        "    # Definimos las transformaciones que se deben aplicar a la imagen para que coincida con el formato MNIST\n",
        "    transformations = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Aplicamos las transformaciones a la imagen\n",
        "    img_transformed = transformations(image)\n",
        "\n",
        "    # Convertimos la imagen para que tenga una dimensión de lote (que PyTorch espera)\n",
        "    img_batch = img_transformed.unsqueeze(0)  # Agrega un batch dimension en la posición 0\n",
        "\n",
        "    # Verificamos las ...\n",
        "    # (Continue your code here, as the last line is incomplete)\n"
      ],
      "metadata": {
        "id": "nZqFgg5fxxZz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Assuming 'images' is a list of PIL Images\n",
        "\n",
        "# Iterate through the list of images and call predict for each one\n",
        "for image in images:\n",
        "    result = predict(image)\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "H6ygC-Uex8KO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 64)  # 28*28 from image dimension\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Vamos a usar torchvision para \"leer\" o predecir los números escritos a mano en el directorio raíz data\\img_6.jpg, data\\img_65.jpg, data\\img_83.jpg\n",
        "# Carga del modelo\n",
        "model = SimpleNet()\n",
        "model.load_state_dict(torch.load('modelo_mnist.pth'))\n",
        "model.eval()  # Importante para decirle al modelo que ahora está en modo de evaluación\n",
        "\n",
        "images = []\n",
        "for root, dirs, files in os.walk('data_prueba'):\n",
        "    for file in files:\n",
        "        base, extension = os.path.splitext(file)\n",
        "        if (extension.lower() == '.jpg'):\n",
        "           full_path = os.path.join(root, file)\n",
        "           images.append(full_path)\n",
        "\n",
        "def predict(image):\n",
        "    # Definimos las transformaciones que se deben aplicar a la imagen para que coincida con el formato MNIST\n",
        "    transformations = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Aplicamos las transformaciones a la imagen\n",
        "    img_transformed = transformations(image)\n",
        "\n",
        "    # Convertimos la imagen para que tenga una dimensión de lote (que PyTorch espera)\n",
        "    img_batch = img_transformed.unsqueeze(0)  # Agrega un batch dimension en la posición 0\n",
        "\n",
        "    # Verificamos las dimensiones de la imagen resultante\n",
        "    print(img_batch.shape)\n",
        "\n",
        "    # Hacer la predicción\n",
        "    with torch.no_grad():  # No necesitamos seguir el rastro de los gradientes\n",
        "        outputs = model(img_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # El resultado 'predicted' es el índice del dígito que el modelo predice\n",
        "    print(f'El modelo predice que el dígito es: {predicted.item()}')\n",
        "\n",
        "for image_path in images:\n",
        "    image = Image.open(image_path)\n",
        "    predict(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOEzfaisyAB7",
        "outputId": "dedc32a9-f296-4f26-ff25-f72645b27bf0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "El modelo predice que el dígito es: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uUy3Heph16nR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}