{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwKvgFzo_Uk_",
        "outputId": "b1374717-359d-45d8-9a15-f77e37700bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The birds sat next to each other on the branch, enjoying the warm spring breeze. One was a vibrant blue with a melodic voice, while the other was a soft yellow with a playful spirit. They were an odd pair, but their differences brought them closer together. Together, they sang the most beautiful duet.\n"
          ]
        }
      ],
      "source": [
        "#!pip install langchain openai langchain-openai google-cloud-secret-manager scipy datasets\n",
        "\n",
        "from transformers import pipeline\n",
        "import scipy\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_openai import OpenAI\n",
        "import torch\n",
        "from IPython.display import Image\n",
        "from datasets import load_dataset\n",
        "# Primero autenticamos el usuario :\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "from google.cloud import secretmanager\n",
        "\n",
        "# Creamos un Cliente de SecretManager:\n",
        "client = secretmanager.SecretManagerServiceClient()\n",
        "secret_name = \"openai-token\"\n",
        "project_id = '196177837977'\n",
        "\n",
        "# Contruimos a F-String:\n",
        "resource_name = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\n",
        "\n",
        "# Obtenemos el secreto :\n",
        "response = client.access_secret_version(request={\"name\": resource_name})\n",
        "secret_string = response.payload.data.decode('UTF-8')\n",
        "\n",
        "llm = OpenAI(openai_api_key=secret_string, temperature=1)\n",
        "\n",
        "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\", max_new_tokens=20)\n",
        "\n",
        "\n",
        "def image2text(image):\n",
        "    text_result = captioner(image)\n",
        "    return text_result[0]['generated_text']\n",
        "\n",
        "def crear_historia(topic):\n",
        "   template = \"\"\"\n",
        "   You are a writer and story teller.\n",
        "   Your task is generate short stories from a shrot description. The story cannot have more than 50 words.\n",
        "   CONTEXT: {topic}\n",
        "   STORY:\n",
        "   \"\"\"\n",
        "   topic_template = PromptTemplate(template=template, input_variables=['topic'])\n",
        "\n",
        "   topic_chain = LLMChain(llm=llm, prompt=topic_template)\n",
        "   response = topic_chain.invoke(topic)\n",
        "   print(response.get('text'))\n",
        "   return response.get('text')\n",
        "\n",
        "def crear_audio(text):\n",
        "  synthesiser = pipeline(\"text-to-speech\", model=\"microsoft/speecht5_tts\")\n",
        "  embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "  speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
        "\n",
        "  speech = synthesiser(f\"{text}\", forward_params={\"speaker_embeddings\": speaker_embedding})\n",
        "\n",
        "  scipy.io.wavfile.write(\"historia.wav\", rate=speech[\"sampling_rate\"], data=speech[\"audio\"])\n",
        "\n",
        "\n",
        "generated_topic = image2text(\"https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\")\n",
        "\n",
        "historia = crear_historia(generated_topic)\n",
        "crear_audio(historia)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POWtrkbBJh9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}