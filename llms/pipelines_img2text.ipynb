{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8de6-E3bS92"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai langchain-openai google-cloud-secret-manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwKvgFzo_Uk_",
        "outputId": "bdbb16f1-4bd8-4407-deec-978566b8e8ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/gustavo.aguado/anaconda3/envs/base_ml/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/gustavo.aguado/anaconda3/envs/base_ml/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "config.json: 100%|██████████| 4.56k/4.56k [00:00<00:00, 2.17MB/s]\n",
            "pytorch_model.bin: 100%|██████████| 990M/990M [00:08<00:00, 115MB/s]  \n",
            "tokenizer_config.json: 100%|██████████| 506/506 [00:00<00:00, 481kB/s]\n",
            "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.17MB/s]\n",
            "tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 1.75MB/s]\n",
            "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 797kB/s]\n",
            "preprocessor_config.json: 100%|██████████| 287/287 [00:00<00:00, 1.74MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'topic': 'two birds are standing next to each other birds', 'text': 'Two birds met each other in the morning. Tired of flying, they stood next to each other on a branch. They chirped and sang songs, marveling at the beautiful sunrise. They then flew off, vowing to meet again the next morning. This became a daily ritual, solidifying their friendship. Together, they soared through the sky, witnessing the wonders of nature. '}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'topic': 'two birds are standing next to each other birds',\n",
              " 'text': 'Two birds met each other in the morning. Tired of flying, they stood next to each other on a branch. They chirped and sang songs, marveling at the beautiful sunrise. They then flew off, vowing to meet again the next morning. This became a daily ritual, solidifying their friendship. Together, they soared through the sky, witnessing the wonders of nature. '}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from IPython.display import Image\n",
        "from transformers import pipeline\n",
        "from langchain import PromptTemplate, LLMChain, OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "# Primero autenticamos el usuario :\n",
        "import sys\n",
        "\n",
        "'''if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()'''\n",
        "\n",
        "#from google.cloud import secretmanager\n",
        "\n",
        "# Creamos un Cliente de SecretManager:\n",
        "#client = secretmanager.SecretManagerServiceClient()\n",
        "#secret_name = \"openai-token\"\n",
        "#project_id = '196177837977'\n",
        "\n",
        "# Contruimos a F-String:\n",
        "##resource_name = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\n",
        "\n",
        "# Obtenemos el secreto :\n",
        "#response = client.access_secret_version(request={\"name\": resource_name})\n",
        "#secret_string = response.payload.data.decode('UTF-8')\n",
        "\n",
        "llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=1)\n",
        "\n",
        "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\", max_new_tokens=20)\n",
        "\n",
        "\n",
        "def image2text(image):\n",
        "    text_result = captioner(image)\n",
        "    return text_result[0]['generated_text']\n",
        "\n",
        "def describir_foto(topic):\n",
        "   template = \"\"\"\n",
        "   You are a writer and story teller.\n",
        "   Your task is generate short stories from a shrot description. The story cannot have more than 50 words.\n",
        "   CONTEXT: {topic}\n",
        "   STORY:\n",
        "   \"\"\"\n",
        "   topic_template = PromptTemplate(template=template, input_variables=['topic'])\n",
        "\n",
        "   topic_chain = LLMChain(llm=llm, prompt=topic_template)\n",
        "   response = topic_chain.invoke(topic)\n",
        "   print(response)\n",
        "   return response\n",
        "\n",
        "generated_topic = image2text(\"https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\")\n",
        "describir_foto(generated_topic)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
